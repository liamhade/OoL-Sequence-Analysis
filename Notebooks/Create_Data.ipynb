{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6a7ad-5b16-4750-a2c0-4ba71cd7c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from Bio import SeqIO\n",
    "import pickle as pkl\n",
    "from cutadapt import adapters, modifiers\n",
    "# from dnaio._core import SequenceRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84b20d-95c1-4a4c-b51e-fd243f4f8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality score cutoff default = 30\n",
    "phred_cutoff = 30\n",
    "# 3'-adaptor: MADAP, 4N or Normal\n",
    "adaptor_3 = \"MADAP\" # or \"Normal\"\n",
    "# 5'-adaptor = 4N for N4_List_Unique or Normal for TCTA\n",
    "adaptor_5 = \"4N\" # 4N or \"Normal\"\n",
    "\n",
    "log = {\"Quality Score Cutoff\": phred_cutoff, \"3'-Adaptor Sequence\": adaptor_3, \"5'-Adaptor\": adaptor_5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081e31e-647f-4d79-b732-4088d5ed85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_folder_names(directory):\n",
    "#     experiment_name = directory.split(sep=\"/\")[-1]\n",
    "\n",
    "#     # Fastq files use the \"-\" instead of the \"_\"\n",
    "#     fastq_readable_name = experiment_name.replace(\"_\", \"-\").upper()\n",
    "\n",
    "#     nice_name = fastq_readable_name[0].upper() + fastq_readable_name[1:].lower()\n",
    "#     nice_name = nice_name.replace(\"-\", \"_\")\n",
    "\n",
    "#     log.update(\n",
    "#         {\"Folder_Name\": directory,\n",
    "#          \"Corrected_Name\": fastq_readable_name,\n",
    "#          \"Nice_Name\": nice_name}\n",
    "#     )\n",
    "\n",
    "#     return experiment_name, fastq_readable_name, nice_name\n",
    "\n",
    "# Folder_Name, Corrected_Name, Nice_Name = get_folder_names(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f545a97-b95e-4123-bd0c-90883fd245be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AC',\n",
       " 'AT',\n",
       " 'CA',\n",
       " 'CC',\n",
       " 'CG',\n",
       " 'GA',\n",
       " 'GC',\n",
       " 'GG',\n",
       " 'GT',\n",
       " 'TC',\n",
       " 'TG',\n",
       " 'ACA',\n",
       " 'ACC',\n",
       " 'ACG',\n",
       " 'ATC',\n",
       " 'ATG',\n",
       " 'CAC',\n",
       " 'CAT',\n",
       " 'CCA',\n",
       " 'CGC',\n",
       " 'CGT',\n",
       " 'GAT',\n",
       " 'GCA',\n",
       " 'GCG',\n",
       " 'GGT',\n",
       " 'GTG',\n",
       " 'TCA',\n",
       " 'TGA',\n",
       " 'TGC',\n",
       " 'TGG',\n",
       " 'TGT',\n",
       " 'ACAC',\n",
       " 'ACCA',\n",
       " 'ACGC',\n",
       " 'ATCA',\n",
       " 'ATGC',\n",
       " 'CACA',\n",
       " 'CACC',\n",
       " 'CACG',\n",
       " 'CATC',\n",
       " 'CCAC',\n",
       " 'CGCA',\n",
       " 'CGTG',\n",
       " 'GATG',\n",
       " 'GCAT',\n",
       " 'GCGT',\n",
       " 'GGTG',\n",
       " 'GTGA',\n",
       " 'GTGG',\n",
       " 'GTGT',\n",
       " 'TCAC',\n",
       " 'TGAT',\n",
       " 'TGCG',\n",
       " 'TGGT',\n",
       " 'TGTG',\n",
       " 'ACACG',\n",
       " 'ACCAC',\n",
       " 'ACGCA',\n",
       " 'ATCAC',\n",
       " 'ATGCG',\n",
       " 'CACAC',\n",
       " 'CACCA',\n",
       " 'CACGC',\n",
       " 'CATCA',\n",
       " 'CCACA',\n",
       " 'CGCAT',\n",
       " 'CGTGT',\n",
       " 'GATGC',\n",
       " 'GCATC',\n",
       " 'GCGTG',\n",
       " 'GGTGA',\n",
       " 'GTGAT',\n",
       " 'GTGGT',\n",
       " 'GTGTG',\n",
       " 'TCACC',\n",
       " 'TGATG',\n",
       " 'TGCGT',\n",
       " 'TGGTG',\n",
       " 'TGTGG',\n",
       " 'ACACGC',\n",
       " 'ACCACA',\n",
       " 'ACGCAT',\n",
       " 'ATCACC',\n",
       " 'ATGCGT',\n",
       " 'CACACG',\n",
       " 'CACCAC',\n",
       " 'CACGCA',\n",
       " 'CATCAC',\n",
       " 'CCACAC',\n",
       " 'CGCATC',\n",
       " 'CGTGTG',\n",
       " 'GATGCG',\n",
       " 'GCATCA',\n",
       " 'GCGTGT',\n",
       " 'GGTGAT',\n",
       " 'GTGATG',\n",
       " 'GTGGTG',\n",
       " 'GTGTGG',\n",
       " 'TCACCA',\n",
       " 'TGATGC',\n",
       " 'TGCGTG',\n",
       " 'TGGTGA',\n",
       " 'TGTGGT',\n",
       " 'ACACGCA',\n",
       " 'ACCACAC',\n",
       " 'ACGCATC',\n",
       " 'ATCACCA',\n",
       " 'ATGCGTG',\n",
       " 'CACACGC',\n",
       " 'CACCACA',\n",
       " 'CACGCAT',\n",
       " 'CATCACC',\n",
       " 'CCACACG',\n",
       " 'CGCATCA',\n",
       " 'CGTGTGG',\n",
       " 'GATGCGT',\n",
       " 'GCATCAC',\n",
       " 'GCGTGTG',\n",
       " 'GGTGATG',\n",
       " 'GTGATGC',\n",
       " 'GTGGTGA',\n",
       " 'GTGTGGT',\n",
       " 'TCACCAC',\n",
       " 'TGATGCG',\n",
       " 'TGCGTGT',\n",
       " 'TGGTGAT',\n",
       " 'TGTGGTG',\n",
       " 'ACACGCAT',\n",
       " 'ACCACACG',\n",
       " 'ACGCATCA',\n",
       " 'ATCACCAC',\n",
       " 'ATGCGTGT',\n",
       " 'CACACGCA',\n",
       " 'CACCACAC',\n",
       " 'CACGCATC',\n",
       " 'CATCACCA',\n",
       " 'CCACACGC',\n",
       " 'CGCATCAC',\n",
       " 'CGTGTGGT',\n",
       " 'GATGCGTG',\n",
       " 'GCATCACC',\n",
       " 'GCGTGTGG',\n",
       " 'GGTGATGC',\n",
       " 'GTGATGCG',\n",
       " 'GTGGTGAT',\n",
       " 'GTGTGGTG',\n",
       " 'TCACCACA',\n",
       " 'TGATGCGT',\n",
       " 'TGCGTGTG',\n",
       " 'TGGTGATG',\n",
       " 'TGTGGTGA',\n",
       " 'ACACGCATC',\n",
       " 'ACCACACGC',\n",
       " 'ACGCATCAC',\n",
       " 'ATCACCACA',\n",
       " 'ATGCGTGTG',\n",
       " 'CACACGCAT',\n",
       " 'CACCACACG',\n",
       " 'CACGCATCA',\n",
       " 'CATCACCAC',\n",
       " 'CCACACGCA',\n",
       " 'CGCATCACC',\n",
       " 'CGTGTGGTG',\n",
       " 'GATGCGTGT',\n",
       " 'GCATCACCA',\n",
       " 'GCGTGTGGT',\n",
       " 'GGTGATGCG',\n",
       " 'GTGATGCGT',\n",
       " 'GTGGTGATG',\n",
       " 'GTGTGGTGA',\n",
       " 'TCACCACAC',\n",
       " 'TGATGCGTG',\n",
       " 'TGCGTGTGG',\n",
       " 'TGGTGATGC',\n",
       " 'TGTGGTGAT',\n",
       " 'ACACGCATCA',\n",
       " 'ACCACACGCA',\n",
       " 'ACGCATCACC',\n",
       " 'ATCACCACAC',\n",
       " 'ATGCGTGTGG',\n",
       " 'CACACGCATC',\n",
       " 'CACCACACGC',\n",
       " 'CACGCATCAC',\n",
       " 'CATCACCACA',\n",
       " 'CCACACGCAT',\n",
       " 'CGCATCACCA',\n",
       " 'CGTGTGGTGA',\n",
       " 'GATGCGTGTG',\n",
       " 'GCATCACCAC',\n",
       " 'GCGTGTGGTG',\n",
       " 'GGTGATGCGT',\n",
       " 'GTGATGCGTG',\n",
       " 'GTGGTGATGC',\n",
       " 'GTGTGGTGAT',\n",
       " 'TCACCACACG',\n",
       " 'TGATGCGTGT',\n",
       " 'TGCGTGTGGT',\n",
       " 'TGGTGATGCG',\n",
       " 'TGTGGTGATG',\n",
       " 'ACACGCATCAC',\n",
       " 'ACCACACGCAT',\n",
       " 'ACGCATCACCA',\n",
       " 'ATCACCACACG',\n",
       " 'ATGCGTGTGGT',\n",
       " 'CACACGCATCA',\n",
       " 'CACCACACGCA',\n",
       " 'CACGCATCACC',\n",
       " 'CATCACCACAC',\n",
       " 'CCACACGCATC',\n",
       " 'CGCATCACCAC',\n",
       " 'CGTGTGGTGAT',\n",
       " 'GATGCGTGTGG',\n",
       " 'GCATCACCACA',\n",
       " 'GCGTGTGGTGA',\n",
       " 'GGTGATGCGTG',\n",
       " 'GTGATGCGTGT',\n",
       " 'GTGGTGATGCG',\n",
       " 'GTGTGGTGATG',\n",
       " 'TCACCACACGC',\n",
       " 'TGATGCGTGTG',\n",
       " 'TGCGTGTGGTG',\n",
       " 'TGGTGATGCGT',\n",
       " 'TGTGGTGATGC',\n",
       " 'ACACGCATCACC',\n",
       " 'ACCACACGCATC',\n",
       " 'ACGCATCACCAC',\n",
       " 'ATCACCACACGC',\n",
       " 'ATGCGTGTGGTG',\n",
       " 'CACACGCATCAC',\n",
       " 'CACCACACGCAT',\n",
       " 'CACGCATCACCA',\n",
       " 'CATCACCACACG',\n",
       " 'CCACACGCATCA',\n",
       " 'CGCATCACCACA',\n",
       " 'CGTGTGGTGATG',\n",
       " 'GATGCGTGTGGT',\n",
       " 'GCATCACCACAC',\n",
       " 'GCGTGTGGTGAT',\n",
       " 'GGTGATGCGTGT',\n",
       " 'GTGATGCGTGTG',\n",
       " 'GTGGTGATGCGT',\n",
       " 'GTGTGGTGATGC',\n",
       " 'TCACCACACGCA',\n",
       " 'TGATGCGTGTGG',\n",
       " 'TGCGTGTGGTGA',\n",
       " 'TGGTGATGCGTG',\n",
       " 'TGTGGTGATGCG']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_short_RNA_strands(vcg_file_path):\n",
    "    # Read lines from the file and remove starting 'p' characters, newline characters, and blank lines.\n",
    "    with open(vcg_file_path, \"r\") as file:\n",
    "        return [line[1:].strip() for line in file.readlines() if line.strip()]\n",
    "\n",
    "def RNA_list_to_DNA(RNAs):\n",
    "    return [str(Seq(seq).back_transcribe()) for seq in RNAs]\n",
    "\n",
    "\n",
    "vcg_file_path = \"../Ext_50\\VCG_List.txt\"\n",
    "VCG_DNA_list = RNA_list_to_DNA(get_short_RNA_strands(vcg_file_path))\n",
    "VCG_DNA_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f99022ba-b08c-47de-a5fd-1154dca7ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving VCG_DNA_list to a pickle for easier access\n",
    "with open(\"VCG_DNA_list.pkl\", \"wb\") as file:\n",
    "    pickle.dump(VCG_DNA_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e65663-a8f7-46d9-9f92-b1283d6c23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_prime_motif(adaptor_5):\n",
    "    '''\n",
    "    Depending on what kind of adaptor was used in the sequencing run,\n",
    "    we will look for different short sequences (aka motifs) in order\n",
    "    to identify the adaptor.\n",
    "\n",
    "    Args:\n",
    "        adaptor_5 (str): The kind of adaptor we are using on the 5' end.\n",
    "\n",
    "    Returns:\n",
    "        What sequence of nucleotides we should look for to identify our adaptor.\n",
    "    '''\n",
    "\n",
    "    all_unique_N4s = [''.join(N4) for N4 in product(\"ACTG\", repeat=4)]\n",
    "\n",
    "    if adaptor_5 == \"4N\":\n",
    "        log.update({\"5'-adaptor: \": adaptor_5, \"N4 combinations\": len(all_unique_N4s)})\n",
    "        return all_unique_N4s\n",
    "\n",
    "    elif adaptor_5 == \"Normal\":\n",
    "        log.update({\"5'-Adaptor: \": adaptor_5, \"5'-Adaptor Sequence\": motif})\n",
    "        return \"TCTA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec0db1-60b7-44a7-b2bc-9d06764acb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_phred(scores):\n",
    "    '''\n",
    "    This function takes a list of Phred quality scores from a read,\n",
    "    converts them into error probabilities and finds the mean,\n",
    "    then converts this average error probability back into an overall\n",
    "    Phred quality score for that read.\n",
    "\n",
    "    Args:\n",
    "        scores (list[int]): List of quality Phred scores for each nucleotide from\n",
    "                            a sequenced read.\n",
    "\n",
    "    Returns:\n",
    "        average_score (int): Average Phred quality score for the entire read\n",
    "    '''\n",
    "\n",
    "    num_records = len(scores)\n",
    "    add_p = 0\n",
    "\n",
    "    # Converting the Phred quality scores into error probabilities\n",
    "    for i in scores:\n",
    "        p = 10 ** (-i / 10)\n",
    "        add_p = add_p + p\n",
    "\n",
    "    p_bar   = add_p / num_records\n",
    "    return -10 * math.log10(p_bar)\n",
    "\n",
    "def filter_reads(read_file, output_directory, output_name):\n",
    "    '''\n",
    "    This function takes in a file of reads and sorts them into those\n",
    "    above and below the Phred cutoff score. Two files are created, one for\n",
    "    for those below the cutoff, and those above the cutoff. These files are\n",
    "    saved into the output_directory.\n",
    "\n",
    "    Args:\n",
    "        read_file (str): Fastq file containing the sequenced reads\n",
    "        output_directory (str): Destination of the output files\n",
    "        output_name: Part of the output names that are shared\n",
    "\n",
    "    Returns:\n",
    "        low_qual (list): Reads with an average Phred score below the cutoff\n",
    "        high_qual (list): Reads with an average Phred score above the cutoff\n",
    "    '''\n",
    "\n",
    "    low_qual = []\n",
    "    high_qual = []\n",
    "    total_reads = 0\n",
    "\n",
    "    for record in SeqIO.parse(f\"{read_file}\", \"fastq\"):\n",
    "        total_reads += 1\n",
    "        scores = record.letter_annotations[\"phred_quality\"]\n",
    "\n",
    "        if average_phred(scores) < phred_cutoff:\n",
    "            low_qual.append(record)\n",
    "        else:\n",
    "            high_qual.append(record)\n",
    "\n",
    "    SeqIO.write(low_qual, f\"{output_directory}/low_quality_{output_name}.fastq\", \"fastq\") # save low quality reads to file\n",
    "    SeqIO.write(high_qual, f\"{output_directory}/high_quality_{output_name}.fastq\", \"fastq\") # save high quality reads to file\n",
    "\n",
    "    percentage_low_qual = (len(low_qual) / total_reads) * 100\n",
    "    percentage_high_qual = (len(high_qual) / total_reads) * 100\n",
    "\n",
    "    print(f\"Number of total reads: {total_reads}\")\n",
    "    print(f\"Number of Low Quality reads written out: {len(low_qual)} ({percentage_low_qual:.2f}%)\")\n",
    "    print(f\"Number of High Quality reads written out: {len(high_qual)} ({percentage_high_qual:.2f}%)\")\n",
    "\n",
    "    log.update({f\"Number of total reads:\": str(total_reads),\n",
    "                f\"Number of Low Quality reads written out:\": (str(len(low_qual)) + f\" ({percentage_low_qual:.2f}%)\"),\n",
    "                f\"Number of High Quality reads written out:\": (str(len(high_qual)) + f\" ({percentage_high_qual:.2f}%)\")})\n",
    "\n",
    "    return low_qual, high_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7302ea-ba29-4668-b9a7-3e9f140bb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a while\n",
    "# Filtering all input reads for high quality reads, low quality reads are\n",
    "directory = \"/work/\"\n",
    "read_file = \"EXT-50_S3_L001_R1_001.fastq\"\n",
    "\n",
    "filter_reads(directory + read_file, directory, \"test_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4faab-ad2f-4ff9-90fe-a254f49cd336",
   "metadata": {},
   "source": [
    "# Creating df_4N on the fly (slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8d9f8-77b9-48c4-b23c-717c5b0eb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.bioinformatics.org/sms/iupac.html\n",
    "\n",
    "'''\n",
    "Find adapters using cutadapt.\n",
    "'''\n",
    "\n",
    "\n",
    "seq_3p = \"AGATCGGAAGAGCACACGTCT\"\n",
    "errors = 0\n",
    "adaptor_3p = adapters.FrontAdapter(sequence=seq_3p,\n",
    "                                    max_errors=errors,\n",
    "                                    adapter_wildcards=True,\n",
    "                                    indels=False)\n",
    "\n",
    "# seq = \"TCTAGTGAATCAGATCGGTTCCGACTAGATCGGAAGAGCACACGTCTGAACTCCAGTCACAGTCAACAATCTC\"\n",
    "# read = SequenceRecord(\n",
    "#         name = \"test_seq\",\n",
    "#         sequence = seq)\n",
    "\n",
    "def format_seq(seq: str, adaptor_3p):\n",
    "    matched_seq = adaptor_3p.match_to(seq)\n",
    "\n",
    "    if matched_seq:\n",
    "        num_errors = matched_seq.errors\n",
    "        adaptor_start = matched_seq.rstart\n",
    "        return seq[0:4] + \"_\" + seq[4:adaptor_start] + \"-\" + seq[adaptor_start:], num_errors\n",
    "    return None\n",
    "\n",
    "high_quality_reads_file = \"..\\Ext_50\\high_quality_Ext_50.fastq\"\n",
    "# format_seq(seq, adaptor_3p) # for troubleshooting\n",
    "\n",
    "formatted_seqs = []\n",
    "for record in SeqIO.parse(high_quality_reads_file, \"fastq\"):\n",
    "    formatted = format_seq(str(record.seq), adaptor_3p)\n",
    "\n",
    "    if formatted:\n",
    "        formatted_seqs.append(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340be84-291b-40b8-9e48-4e47ceb1c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = []\n",
    "errs = []\n",
    "for seq, err in formatted_seqs:\n",
    "    seqs.append(seq)\n",
    "    errs.append(err)\n",
    "\n",
    "df_4N = pd.DataFrame({\"Seq\": seqs, \"Errors\":errs})\n",
    "df_4N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6985d3-275f-4a9c-a968-d9eb1d354ef6",
   "metadata": {},
   "source": [
    "# Loading df_4N from file (quicker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6425f-d553-4efb-a199-d22fbd06d159",
   "metadata": {},
   "source": [
    "Using Pandas vectorization methods instead of .apply() to edit our DataFrame because it is generally much more effeciant on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd9609-cc9c-4665-ac99-9bcde4803845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4N = pd.read_csv(\"..\\Ext_50\\_deepnote_work_4N.csv.gz\")\n",
    "\n",
    "df_4N[\"5_Adap\"] = df_4N[\"Seq\"].str[:4]\n",
    "df_4N[\"Less_3\"] = df_4N[\"Seq\"].str.split(\"-\", n=1).str[0]\n",
    "\n",
    "df_4N[\"Spacer\"]     = df_4N[\"Less_3\"].str[-2:]\n",
    "df_4N[\"Rand_4\"]     = df_4N[\"Less_3\"].str[-6:-2]\n",
    "df_4N[\"MADAP_Code\"] = df_4N[\"Less_3\"].str[-9:-6]\n",
    "df_4N[\"Bind_6\"]     = df_4N[\"Less_3\"].str[-15:-9]\n",
    "df_4N[\"4N\"]         = df_4N[\"Less_3\"].str[-19:-15]\n",
    "df_4N[\"Pre_VCG\"]    = df_4N[\"Less_3\"].str[:-19]\n",
    "\n",
    "df_4N[\"VCG\"]     = df_4N[\"Pre_VCG\"].str[5:]\n",
    "df_4N[\"VCG_Len\"] = df_4N[\"VCG\"].str.len()\n",
    "df_4N[\"3_Adap\"]  = df_4N[\"Seq\"].str[5:].str.split(\"-\", n=1).str[1].str[:21]\n",
    "df_4N[\"UMI\"]     = df_4N[\"4N\"] + df_4N[\"Rand_4\"]\n",
    "\n",
    "log.update({\"No. of reads with adaptors\":df_4N.shape[0]})\n",
    "\n",
    "# Reordering the dataframe for me intuitive reading\n",
    "df_4N = df_4N[[\"Seq\", \"Errors\", \"5_Adap\", \"VCG\", \"VCG_Len\", \"4N\", \"Bind_6\", \"MADAP_Code\", \"Rand_4\", \"Spacer\", \"3_Adap\", \"UMI\"]]\n",
    "df_4N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba232f8-10bc-42b2-bfa1-e627ad9e4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4N_reduced = df_4N.query(\"VCG_Len != 0\")\n",
    "log.update({\"No. of reads with 'VCG' Length > 0\":df_4N_reduced.shape[0]})\n",
    "df_4N_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ca6dc-74c2-4674-b729-09ab0b3fc6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4N_VCG = df_4N_reduced.query(\"VCG in @VCG_DNA_list\")\n",
    "log.update({\"No. of reads in VCG\":df_4N_VCG.shape[0]})\n",
    "df_4N_VCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359051a2-ef9a-4653-950a-85024b6472c2",
   "metadata": {},
   "source": [
    "## Saving our three dataframes (4N, VCG, and reduced) to pkl files so they can quickly and easily be accessed in other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4738e20a-1ac2-4ff6-8530-52f81d25cfa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "write to closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     pkl\u001b[38;5;241m.\u001b[39mdump(df_4N_reduced, file_2)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_4N_VCG.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_3:\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mpkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_4N_VCG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_1\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: write to closed file"
     ]
    }
   ],
   "source": [
    "# Only need to run this once\n",
    "\n",
    "with open(\"df_4N.pkl\", \"wb\") as file_1:\n",
    "    pkl.dump(df_4N, file_1)\n",
    "\n",
    "with open(\"df_4N_reduced.pkl\", \"wb\") as file_2:\n",
    "    pkl.dump(df_4N_reduced, file_2)\n",
    "\n",
    "with open(\"df_4N_VCG.pkl\", \"wb\") as file_3:\n",
    "    pkl.dump(df_4N_VCG, file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c3947-b646-4686-a43c-1b2c0d5a3875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ool_lab_venv",
   "language": "python",
   "name": "ool_lab_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
